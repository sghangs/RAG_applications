{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Self-RAG: A Dynamic Approach to Retrieval-Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self-RAG is an advanced algorithm that combines the power of retrieval-based and generation-based approaches in natural language processing. It dynamically decides whether to use retrieved information and how to best utilize it in generating responses, aiming to produce more accurate, relevant, and useful outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method Details\n",
    "1. Retrieval Decision: The algorithm first decides if retrieval is necessary for the given query. This step prevents unnecessary retrieval for queries that can be answered directly.\n",
    "\n",
    "2. Document Retrieval: If retrieval is deemed necessary, the algorithm fetches the top-k most similar documents from a vector store.\n",
    "\n",
    "3. Relevance Evaluation: Each retrieved document is evaluated for its relevance to the query. This step filters out irrelevant information, ensuring that only pertinent context is used for generation.\n",
    "\n",
    "4. Response Generation: The algorithm generates responses using the relevant contexts. If no relevant contexts are found, it generates a response without retrieval.\n",
    "\n",
    "5. Support Assessment: Each generated response is evaluated to determine how well it is supported by the context. This step helps in identifying responses that are grounded in the provided information.\n",
    "\n",
    "6. Utility Evaluation: The utility of each response is rated, considering how well it addresses the original query.\n",
    "\n",
    "7. Response Selection: The final step involves selecting the best response based on the support assessment and utility evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from utility import encode_pdf, show_context, retrieve_context_per_question\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from typing import List, Any, Dict\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from tqdm import tqdm\n",
    "from langchain.vectorstores import Chroma, FAISS\n",
    "import faiss\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
    "from utility import replace_t_with_space\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "import pymupdf\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sunny\\Desktop\\Langchain_projects\\Q&A_chatbot\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "file_path=\"data/Understanding_Climate_Change.pdf\"\n",
    "vector_store = encode_pdf(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"llama-3.1-8b-instant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define prompts and chain for each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Schema and prompt for retrieval response \n",
    "class RetrievalResponse(BaseModel):\n",
    "    response:str = Field(description=\"Determine if retrieval is necessary. The answer should be 'yes' or 'no'\")\n",
    "\n",
    "retrieval_prompt = PromptTemplate(\n",
    "    template = \"Given the query '{query}', determine if retrieval is necessary. Output only 'Yes' or 'No'.\",\n",
    "    input_variables=[\"query\"]\n",
    ")\n",
    "\n",
    "#Schema and prompt for relevance response \n",
    "class RelevanceResponse(BaseModel):\n",
    "    response:str = Field(description=\"Determine if context is relevant. The answer should be 'yes' or 'no'\")\n",
    "\n",
    "relevance_prompt = PromptTemplate(\n",
    "    template = \"Given the query '{query}' and the context '{context}', determine if the context is relevant. Output only 'Relevant' or 'Irrelevant'\",\n",
    "    input_variables=[\"query\",\"context\"]\n",
    ")\n",
    "\n",
    "#Schema and prompt for Generation response \n",
    "#class GenerationResponse(BaseModel):\n",
    "#    response:str = Field(description=\"Generated response from llm. Output should be string\")\n",
    "\n",
    "generation_prompt = PromptTemplate(\n",
    "    template = \"Given the query '{query}' and the context '{context}', generate a response.\",\n",
    "    input_variables=[\"query\",\"context\"]\n",
    ")\n",
    "\n",
    "#Schema and prompt for support response \n",
    "class SupportResponse(BaseModel):\n",
    "    response:str = Field(description=\"Determines if response is supported. Output 'Fully supported', 'Partially supported', or 'No support'\")\n",
    "\n",
    "support_prompt = PromptTemplate(\n",
    "    template = \"\"\"Given the response '{response}' and the context '{context}', \n",
    "    determine if the response is supported by the context. Output 'Fully supported', \n",
    "    'Partially supported', or 'No support'.\"\"\",\n",
    "    input_variables=[\"response\",\"context\"]\n",
    ")\n",
    "#Schema and prompt for utility response\n",
    "class UtilityResponse(BaseModel):\n",
    "    response: int = Field(description=\"Rate the utility of the response from 1 to 5\")\n",
    "utility_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"response\"],\n",
    "    template=\"Given the query '{query}' and the response '{response}', rate the utility of the response from 1 to 5.\"\n",
    ")\n",
    "\n",
    "# Create LLMChains for each step\n",
    "retrieval_chain = retrieval_prompt | llm.with_structured_output(RetrievalResponse)\n",
    "relevance_chain = relevance_prompt | llm.with_structured_output(RelevanceResponse)\n",
    "#generation_chain = generation_prompt | llm.with_structured_output(GenerationResponse)\n",
    "generation_chain = generation_prompt | llm | StrOutputParser()\n",
    "support_chain = support_prompt | llm.with_structured_output(SupportResponse)\n",
    "utility_chain = utility_prompt | llm.with_structured_output(UtilityResponse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining the self RAG logic flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_rag(query,vectorstore,top_k=3):\n",
    "    print(f\"\\n Processing query : {query}\")\n",
    "\n",
    "    #step:1 Determine if retrieval is necessary\n",
    "    print(\"Step 1: Determining if retrieval is necessary...\")\n",
    "    input_data = {\"query\": query}\n",
    "    retrieval_decision = retrieval_chain.invoke(input_data).response.strip().lower()\n",
    "    print(f\"Retrieval decision: {retrieval_decision}\")\n",
    "\n",
    "    if retrieval_decision == 'yes':\n",
    "        # Step 2: Retrieve relevant documents\n",
    "        print(\"Step 2: Retrieving relevant documents...\")\n",
    "        docs = vectorstore.similarity_search(query, k=top_k)\n",
    "        contexts = [doc.page_content for doc in docs]\n",
    "        print(f\"Retrieved {len(contexts)} documents\")\n",
    "\n",
    "        # Step 3: Evaluate relevance of retrieved documents\n",
    "        print(\"Step 3: Evaluating relevance of retrieved documents...\")\n",
    "        relevant_contexts = []\n",
    "        for i, context in enumerate(contexts):\n",
    "            input_data = {\"query\": query, \"context\": context}\n",
    "            relevance = relevance_chain.invoke(input_data).response.strip().lower()\n",
    "            print(f\"Document {i+1} relevance: {relevance}\")\n",
    "            if relevance == 'yes':\n",
    "                relevant_contexts.append(context)\n",
    "        \n",
    "        print(f\"Number of relevant contexts: {len(relevant_contexts)}\")\n",
    "\n",
    "        # If no relevant contexts found, generate without retrieval\n",
    "        if not relevant_contexts:\n",
    "            print(\"No relevant contexts found. Generating without retrieval...\")\n",
    "            input_data = {\"query\": query, \"context\": \"No relevant context found.\"}\n",
    "            return generation_chain.invoke(input_data)\n",
    "        \n",
    "        # Step 4: Generate response using relevant contexts\n",
    "        print(\"Step 4: Generating responses using relevant contexts...\")\n",
    "        responses = []\n",
    "        for i, context in enumerate(relevant_contexts):\n",
    "            print(f\"Generating response for context {i+1}...\")\n",
    "            input_data = {\"query\": query, \"context\": context}\n",
    "            response = generation_chain.invoke(input_data)\n",
    "\n",
    "            # Step 5: Assess support\n",
    "            print(f\"Step 5: Assessing support for response {i+1}...\")\n",
    "            input_data = {\"response\": response, \"context\": context}\n",
    "            support = support_chain.invoke(input_data).response.strip().lower()\n",
    "            print(f\"Support assessment: {support}\")\n",
    "\n",
    "            # Step 6: Evaluate utility\n",
    "            print(f\"Step 6: Evaluating utility for response {i+1}...\")\n",
    "            input_data = {\"query\": query, \"response\": response}\n",
    "            utility = int(utility_chain.invoke(input_data).response)\n",
    "            print(f\"Utility score: {utility}\")\n",
    "            \n",
    "            responses.append((response, support, utility))\n",
    "\n",
    "        # Select the best response based on support and utility\n",
    "        print(\"Selecting the best response...\")\n",
    "        best_response = max(responses, key=lambda x: (x[1] == 'fully supported', x[2]))\n",
    "        print(f\"Best response support: {best_response[1]}, utility: {best_response[2]}\")\n",
    "        return best_response[0]\n",
    "    else:\n",
    "        # Generate without retrieval\n",
    "        print(\"Generating without retrieval...\")\n",
    "        input_data = {\"query\": query, \"context\": \"No retrieval necessary.\"}\n",
    "        return generation_chain.invoke(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processing query : What is the impact of climate change on the environment?\n",
      "Step 1: Determining if retrieval is necessary...\n",
      "Retrieval decision: yes\n",
      "Step 2: Retrieving relevant documents...\n",
      "Retrieved 3 documents\n",
      "Step 3: Evaluating relevance of retrieved documents...\n",
      "Document 1 relevance: yes\n",
      "Document 2 relevance: yes\n",
      "Document 3 relevance: yes\n",
      "Number of relevant contexts: 3\n",
      "Step 4: Generating responses using relevant contexts...\n",
      "Generating response for context 1...\n",
      "Step 5: Assessing support for response 1...\n",
      "Support assessment: the impact of climate change on the environment is multifaceted and far-reaching.\n",
      "Step 6: Evaluating utility for response 1...\n",
      "Utility score: 5\n",
      "Generating response for context 2...\n",
      "Step 5: Assessing support for response 2...\n",
      "Support assessment: content='the impact of climate change on the environment is multifaceted and far-reaching. climate change is altering terrestrial ecosystems by shifting habitat ranges, changing species distributions, and impacting ecosystem functions. this can lead to a loss of biodiversity and disrupt ecological balance.\n",
      "\n",
      "on land, forests, grasslands, and deserts are experiencing shifts in plant and animal species composition. as a result, these ecosystems are becoming less resilient and more vulnerable to natural disasters and invasive species. the loss of biodiversity can also have significant economic and social implications, particularly for communities that rely heavily on natural resources for their livelihoods.\n",
      "\n",
      "in marine ecosystems, the impacts of climate change are equally severe. rising sea temperatures, ocean acidification, and changing currents are affecting marine biodiversity, from coral reefs to deep-sea habitats. these changes can disrupt marine food webs and fisheries, which are critical for the livelihoods of millions of people around the world.\n",
      "\n",
      "the consequences of climate change extend beyond the ecosystems themselves, with far-reaching implications for human health, food security, and economic development. it is essential that we take immediate action to reduce greenhouse gas emissions and mitigate the impacts of climate change on the environment. this can be achieved through a combination of technological innovation, policy changes, and behavioral shifts.\n",
      "\n",
      "some potential strategies for addressing the impacts of climate change on the environment include:\n",
      "\n",
      "1. protecting and restoring natural habitats, such as forests and wetlands, to maintain biodiversity and ecosystem resilience.\n",
      "2. implementing sustainable fishing and aquaculture practices to maintain healthy marine ecosystems and fisheries.\n",
      "3. promoting climate-resilient agriculture and land-use practices to reduce the vulnerability of agricultural systems to climate change.\n",
      "4. supporting climate change research and development to identify effective solutions and technologies for mitigating and adapting to climate change.\n",
      "5. encouraging individual and collective action to reduce greenhouse gas emissions and promote sustainable lifestyles.\n",
      "\n",
      "ultimately, addressing the impacts of climate change on the environment requires a collaborative and multifaceted approach that involves governments, businesses, civil society, and individuals working together to reduce emissions, promote sustainability, and build resilience.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 415, 'prompt_tokens': 177, 'total_tokens': 592, 'completion_time': 0.553333333, 'prompt_time': 0.006495565, 'queue_time': 0.12047187399999999, 'total_time': 0.559828898}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f7bd09b454', 'finish_reason': 'stop', 'logprobs': none} id='run-1649fa17-16c5-4444-82fb-fed7ca2f4446-0' usage_metadata={'input_tokens': 177, 'output_tokens': 415, 'total_tokens': 592}' and the context 'climate change is altering terrestrial ecosystems by shifting habitat ranges, changing species distributions, and impacting ecosystem functions. forests, grasslands, and deserts are experiencing shifts in plant and animal species composition. these changes can lead to a loss of biodiversity and disrupt ecological balance. \n",
      "\n",
      "marine ecosystems \n",
      "marine ecosystems are highly vulnerable to climate change. rising sea temperatures, ocean acidification, and changing currents affect marine biodiversity, from coral reefs to deep-sea habitats. species migration and changes in reproductive cycles can disrupt marine food webs and fisheries.'\n",
      "Step 6: Evaluating utility for response 2...\n",
      "Utility score: 4\n",
      "Generating response for context 3...\n",
      "Step 5: Assessing support for response 3...\n",
      "Support assessment: fully supported\n",
      "Step 6: Evaluating utility for response 3...\n",
      "Utility score: 5\n",
      "Selecting the best response...\n",
      "Best response support: fully supported, utility: 5\n",
      "\n",
      "Final response:\n",
      "content=\"Based on the given query and context, here's a detailed response on the impact of climate change on the environment, with a focus on the agricultural sector:\\n\\nThe impact of climate change on the environment is multifaceted and far-reaching. Rising global temperatures, heatwaves, and changing seasons are some of the most significant effects of climate change, which are already being felt worldwide and are projected to intensify in the coming decades.\\n\\nThe agricultural sector, in particular, is vulnerable to the impacts of climate change. Rising temperatures and changing precipitation patterns can lead to crop failures, reduced yields, and decreased agricultural productivity. This can have devastating effects on food security, especially in regions where the agricultural sector is a significant contributor to the economy and livelihoods.\\n\\nMoreover, climate change can alter the distribution and prevalence of pests and diseases that affect crops, further exacerbating the challenges faced by farmers. For instance, warmer temperatures can lead to an increase in the spread of diseases such as wheat rust and potato blight, which can decimate entire crops.\\n\\nThe consequences of climate change on the environment are not limited to the agricultural sector. Rising global temperatures can also lead to more frequent and severe heatwaves, which can have devastating effects on human health, especially for vulnerable populations such as the elderly, young children, and people with pre-existing medical conditions.\\n\\nFurthermore, climate change can alter the timing and length of seasons, affecting ecosystems and human activities such as migration patterns, water cycles, and natural disasters. For example, changing seasonal patterns can lead to an increase in wildfires, floods, and droughts, which can have devastating effects on communities and ecosystems.\\n\\nIn light of these challenges, the development of eco-friendly fertilizers and farming techniques is indeed essential for reducing the agricultural sector's carbon footprint. Some examples of eco-friendly farming practices include:\\n\\n1. Agroforestry: Planting trees alongside crops to reduce soil erosion and increase biodiversity.\\n2. Regenerative agriculture: Using practices such as no-till or reduced-till farming to reduce soil degradation and increase soil organic matter.\\n3. Integrated pest management: Using a combination of techniques such as crop rotation, biological control, and cultural controls to manage pests and diseases.\\n4. Organic farming: Using natural methods to control pests and diseases, rather than synthetic pesticides and fertilizers.\\n\\nBy adopting these eco-friendly farming practices, farmers can reduce their carbon footprint, improve soil health, and promote biodiversity, ultimately contributing to a more sustainable and resilient agricultural sector.\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 495, 'prompt_tokens': 246, 'total_tokens': 741, 'completion_time': 0.66, 'prompt_time': 0.025689485, 'queue_time': 1.028580254, 'total_time': 0.685689485}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f7bd09b454', 'finish_reason': 'stop', 'logprobs': None} id='run-b67db69b-b3a4-44fe-a188-9f2da2481bf8-0' usage_metadata={'input_tokens': 246, 'output_tokens': 495, 'total_tokens': 741}\n"
     ]
    }
   ],
   "source": [
    "#Test teh self RAG\n",
    "query = \"What is the impact of climate change on the environment?\"\n",
    "response = self_rag(query, vector_store)\n",
    "\n",
    "print(\"\\nFinal response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processing query : how did harry beat quirrell?\n",
      "Step 1: Determining if retrieval is necessary...\n",
      "Retrieval decision: yes\n",
      "Step 2: Retrieving relevant documents...\n",
      "Retrieved 3 documents\n",
      "Step 3: Evaluating relevance of retrieved documents...\n",
      "Document 1 relevance: irrelevant\n",
      "Document 2 relevance: irrelevant\n",
      "Document 3 relevance: irrelevant\n",
      "Number of relevant contexts: 0\n",
      "No relevant contexts found. Generating without retrieval...\n",
      "\n",
      "Final response:\n",
      "content=\"I'd be happy to help you with that.  However, I must inform you that I couldn't find any relevant context for your question. Nonetheless, I can provide a general response.\\n\\nHarry Potter managed to defeat Lord Voldemort (not Quirrell) in their final battle. However, if you are asking about the battle between Harry Potter and Quirrell, it's because Quirrell possessed Voldemort's physical form at the time.\\n\\nIn the book 'Harry Potter and the Philosopher's Stone,' Harry Potter defeats Quirrell with the help of his mother's love. When Voldemort attempted to return to power through the Philosopher's Stone, he possessed the body of Professor Quirrell. Since Voldemort was trying to regain his physical form through the stone, he was weakened and unable to fully control Quirrell's body. \\n\\nHarry, who unknowingly possessed a piece of Voldemort's soul, was able to resist the Dark Lord's attempts to return to power. In the end, it was Harry's mother's love that proved to be the key to defeating Voldemort's attempt to return to power through Quirrell's body.\\n\\nIf you are looking for more information or clarification on this topic, please provide more context, and I will be happy to help.\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 255, 'prompt_tokens': 60, 'total_tokens': 315, 'completion_time': 0.384496214, 'prompt_time': 0.003120219, 'queue_time': 0.05087404, 'total_time': 0.387616433}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_a4265e44d5', 'finish_reason': 'stop', 'logprobs': None} id='run-959de96a-f0bd-41d2-9e87-f4922dff711e-0' usage_metadata={'input_tokens': 60, 'output_tokens': 255, 'total_tokens': 315}\n"
     ]
    }
   ],
   "source": [
    "query = \"how did harry beat quirrell?\"\n",
    "response = self_rag(query, vector_store)\n",
    "\n",
    "print(\"\\nFinal response:\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
