{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contextual Chunk Headers (CCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview\n",
    "Contextual chunk headers (CCH) is a method of creating chunk headers that contain higher-level context (such as document-level or section-level context), and prepending those chunk headers to the chunks prior to embedding them. This gives the embeddings a much more accurate and complete representation of the content and meaning of the text. In our testing, this feature leads to a substantial improvement in retrieval quality. In addition to increasing the rate at which the correct information is retrieved, CCH also reduces the rate at which irrelevant results show up in the search results. This reduces the rate at which the LLM misinterprets a piece of text in downstream chat and generation applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from utility import encode_pdf, show_context, retrieve_context_per_question\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from typing import List\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from tqdm import tqdm\n",
    "from langchain.vectorstores import Chroma, FAISS\n",
    "import faiss\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
    "from utility import replace_t_with_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/nike_2023_annual_report.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the document and split it into chunks\n",
    "with open(file_path, \"r\",encoding=\"utf8\") as file:\n",
    "    document_text = file.read()\n",
    "\n",
    "def split_into_chunks(docs_text,chunk_size:int = 1000) -> list[str]:\n",
    "    \"\"\"\n",
    "    Split a given text into chunks of specified size using RecursiveCharacterTextSplitter.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be split into chunks.\n",
    "        chunk_size (int, optional): The maximum size of each chunk. Defaults to 800.\n",
    "\n",
    "    Returns:\n",
    "        list[str]: A list of text chunks.\n",
    "\n",
    "    Example:\n",
    "        >>> text = \"This is a sample text to be split into chunks.\"\n",
    "        >>> chunks = split_into_chunks(text, chunk_size=10)\n",
    "        >>> print(chunks)\n",
    "        ['This is a', 'sample', 'text to', 'be split', 'into', 'chunks.']\n",
    "    \"\"\"\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = chunk_size,\n",
    "        chunk_overlap = 100,\n",
    "        length_function = len\n",
    "    )\n",
    "\n",
    "    docs = splitter.create_documents([docs_text])\n",
    "    return [doc.page_content for doc in docs]\n",
    "\n",
    "chunks = split_into_chunks(document_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_docs = chunks[0:100]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12ab9b366ad6c6c880fffbd1a9e1c0ba9825d2f9bd67635de77c6498f87926fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
