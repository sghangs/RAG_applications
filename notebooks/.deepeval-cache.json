{"test_cases_lookup_map": {"{\"actual_output\": \"Sheryl Baxter works for Rasmussen Group\", \"context\": null, \"expected_output\": null, \"hyperparameters\": null, \"input\": \"which company does sheryl Baxter work for?\", \"retrieval_context\": null}": {"cached_metrics_data": [{"metric_data": {"name": "Answer Relevancy", "threshold": 0.7, "success": true, "score": 1.0, "reason": "The score is 1.00 because the provided output perfectly matches the input question with high precision and no irrelevant statements.", "strictMode": false, "evaluationModel": "gpt-4o", "evaluationCost": 0, "verboseLogs": "Statements:\n[\n    \"Sheryl Baxter works for Rasmussen Group.\"\n] \n \nVerdicts:\n[\n    {\n        \"verdict\": \"yes\",\n        \"reason\": null\n    }\n]"}, "metric_configuration": {"threshold": 0.7, "evaluation_model": "gpt-4o", "strict_mode": false, "include_reason": true}}]}, "{\"actual_output\": \"It depends, some might consider the cat, while others might argue the dog.\", \"context\": null, \"expected_output\": \"The cat.\", \"hyperparameters\": null, \"input\": \"The dog chased the cat up the tree, who ran up the tree?\", \"retrieval_context\": null}": {"cached_metrics_data": [{"metric_data": {"name": "correctness (GEval)", "threshold": 0.5, "success": false, "score": 0.23650124897758448, "reason": "The actual output introduces ambiguity by suggesting both the cat and the dog, while the expected output clearly states the cat ran up the tree.", "strictMode": false, "evaluationModel": "gpt-4o", "evaluationCost": 0, "verboseLogs": "Criteria:\nDetermine whether the actual output is factually correct based on the expected output. \n \nEvaluation Steps:\n[\n    \"Compare the factual details in the actual output against the expected output.\",\n    \"Identify any discrepancies between the actual output and the expected output.\",\n    \"Evaluate whether the actual output provides accurate information as specified in the expected output.\",\n    \"Determine if the actual output meets the factual correctness criteria based on the expected output.\"\n]"}, "metric_configuration": {"threshold": 0.5, "evaluation_model": "gpt-4o", "strict_mode": false, "criteria": "Determine whether the actual output is factually correct based on the expected output.", "include_reason": false, "evaluation_steps": ["Compare the factual details in the actual output against the expected output.", "Identify any discrepancies between the actual output and the expected output.", "Evaluate whether the actual output provides accurate information as specified in the expected output.", "Determine if the actual output meets the factual correctness criteria based on the expected output."], "evaluation_params": ["input", "actual_output", "expected_output"]}}]}}}