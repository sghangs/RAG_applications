{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fusion Retrieval in Document Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code implements a Fusion Retrieval system that combines vector-based similarity search with keyword-based BM25 retrieval. The approach aims to leverage the strengths of both methods to improve the overall quality and relevance of document retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traditional retrieval methods often rely on either semantic understanding (vector-based) or keyword matching (BM25). Each approach has its strengths and weaknesses. Fusion retrieval aims to combine these methods to create a more robust and accurate retrieval system that can handle a wider range of queries effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from utility import encode_pdf, show_context, retrieve_context_per_question\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from typing import List\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from tqdm import tqdm\n",
    "from langchain.vectorstores import Chroma, FAISS\n",
    "import faiss\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
    "from utility import replace_t_with_space\n",
    "from langchain_experimental.text_splitter import SemanticChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"data/Understanding_Climate_Change.pdf\"\n",
    "def encode_pdf_split_documents(path,chunk_size=1000,chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Encodes a PDF book into a vector store using HuggingFace embeddings.\n",
    "\n",
    "    Args:\n",
    "        path: The path to the PDF file.\n",
    "        chunk_size: The desired size of each text chunk.\n",
    "        chunk_overlap: The amount of overlap between consecutive chunks.\n",
    "\n",
    "    Returns:\n",
    "        A FAISS vector store containing the encoded book content.\n",
    "    \"\"\"\n",
    "    #Load the Pdf file \n",
    "    loader=PyPDFLoader(path)\n",
    "    docs=loader.load()\n",
    "\n",
    "    #Split the documents into chunks\n",
    "    splitter=RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len\n",
    "    )\n",
    "\n",
    "    texts=splitter.split_documents(docs)\n",
    "    cleaned_texts=replace_t_with_space(texts)\n",
    "\n",
    "    #Embeddings \n",
    "    embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    #Create vector store\n",
    "    vectorstore=FAISS.from_documents(cleaned_texts,embeddings)\n",
    "\n",
    "    return vectorstore,cleaned_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sunny\\Desktop\\Langchain_projects\\Q&A_chatbot\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "vectorstore, cleaned_texts = encode_pdf_split_documents(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create BM25 index for retriving documents by keywords\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "def create_bm25_index(documents :List[Document]) -> BM25Okapi:\n",
    "    \"\"\"\n",
    "    Create a BM25 index from the given documents.\n",
    "\n",
    "    BM25 (Best Matching 25) is a ranking function used in information retrieval.\n",
    "    It's based on the probabilistic retrieval framework and is an improvement over TF-IDF.\n",
    "\n",
    "    Args:\n",
    "    documents (List[Document]): List of documents to index.\n",
    "\n",
    "    Returns:\n",
    "    BM25Okapi: An index that can be used for BM25 scoring.\n",
    "    \"\"\"\n",
    "    tokenize_doc = [doc.page_content.split() for doc in documents]\n",
    "    return BM25Okapi(tokenize_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = create_bm25_index(cleaned_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Function that retrieved both semantically and by keyword and normalize the scores and get the top k documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion_retrieval(vectorstore,bm25,query:str,k:int = 5,alpha:float = 0.5) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Perform fusion retrieval combining keyword-based (BM25) and vector-based search.\n",
    "\n",
    "    Args:\n",
    "    vectorstore (VectorStore): The vectorstore containing the documents.\n",
    "    bm25 (BM25Okapi): Pre-computed BM25 index.\n",
    "    query (str): The query string.\n",
    "    k (int): The number of documents to retrieve.\n",
    "    alpha (float): The weight for vector search scores (1-alpha will be the weight for BM25 scores).\n",
    "\n",
    "    Returns:\n",
    "    List[Document]: The top k documents based on the combined scores.\n",
    "    \"\"\"\n",
    "\n",
    "    epsilon = 1e-8\n",
    "    #Step:1 Get all the documents from vectorstore\n",
    "    all_docs = vectorstore.similarity_search(\"\",k=vectorstore.index.ntotal)\n",
    "\n",
    "    #Step:2 Perform BM25 search\n",
    "    bm25_scores = bm25.get_scores(query.split())\n",
    "\n",
    "    #Step:3 Perform vector search\n",
    "    vector_results = vectorstore.similarity_search_with_score(query,k=len(all_docs))    \n",
    "\n",
    "    #Step:4 Normalize scores\n",
    "    vector_scores = np.array([score for _,score in vector_results])\n",
    "    vector_scores = 1 - (vector_scores - np.min(vector_scores)) / (np.max(vector_scores) - np.min(vector_scores) + epsilon)\n",
    "\n",
    "    bm25_scores = (bm25_scores - np.min(bm25_scores)) / (np.max(bm25_scores) -  np.min(bm25_scores) + epsilon)\n",
    "\n",
    "    # Step 5: Combine scores\n",
    "    combined_scores = alpha * vector_scores + (1 - alpha) * bm25_scores\n",
    "\n",
    "    # Step 6: Rank documents\n",
    "    sorted_indices = np.argsort(combined_scores)[::-1]\n",
    "    \n",
    "    # Step 7: Return top k documents\n",
    "    return [all_docs[i] for i in sorted_indices[:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context 1:\n",
      "Journalists and media organizations play a key role in informing the public about climate \n",
      "change. Investigative reporting, in-depth analysis, and human-interest stories can highlight \n",
      "the urgency and impacts of climate change. Media coverage can also hold policymakers and \n",
      "businesses accountable. \n",
      "Public Engagement \n",
      "Public engagement initiatives, such as citizen science projects, forums, and dialogues, \n",
      "encourage active participation in climate action. These initiatives provide platforms for \n",
      "sharing knowledge, experiences, and ideas. Engaging the public fosters a sense of ownership \n",
      "and responsibility. \n",
      "Chapter 12: The Path Forward\n",
      "\n",
      "\n",
      "Context 2:\n",
      "Carbon Pricing \n",
      "Carbon pricing mechanisms, such as carbon taxes and cap-and-trade systems, incentivize \n",
      "emission reductions by assigning a cost to carbon emissions. These policies encourage \n",
      "businesses and individuals to reduce their carbon footprints and invest in cleaner \n",
      "technologies. \n",
      "Renewable Energy Targets \n",
      "Many countries have set ambitious targets for renewable energy adoption. These targets are \n",
      "supported by policies such as subsidies, tax incentives, and mandates for renewable energy \n",
      "use. Achieving these targets requires robust infrastructure and market development. \n",
      "Emission Reduction Regulations \n",
      "Governments implement regulations to limit emissions from key sectors such as energy, \n",
      "transportation, and industry. These regulations can include efficiency standards, emission \n",
      "caps, and pollution controls. Enforcement and compliance are critical for their effectiveness. \n",
      "Local and Community Initiatives \n",
      "Urban Climate Action\n",
      "\n",
      "\n",
      "Context 3:\n",
      "Developing advanced materials that enhance energy efficiency and reduce emissions is a key \n",
      "area of innovation. Examples include high-performance insulation materials, lightweight \n",
      "composites for transportation, and sustainable building materials. These innovations \n",
      "contribute to energy savings and lower carbon footprints. \n",
      "Social Innovation \n",
      "Behavioral Change Programs \n",
      "Programs that encourage behavioral change towards more sustainable lifestyles are vital for \n",
      "reducing emissions and promoting resilience. This includes initiatives that promote energy \n",
      "conservation, sustainable consumption, and waste reduction. Behavioral change programs \n",
      "often use social marketing, education, and incentives to influence actions. \n",
      "Community-Based Solutions\n",
      "\n",
      "\n",
      "Context 4:\n",
      "community involvement. Partnerships with local organizations, businesses, and governments \n",
      "enhance the reach and impact of these efforts. \n",
      "Advocacy and Activism \n",
      "Grassroots Movements \n",
      "Grassroots movements, driven by passionate individuals and groups, play a critical role in \n",
      "advocating for climate action. These movements can raise awareness, influence policy, and \n",
      "mobilize communities. Successful campaigns often use creative and innovative approaches to \n",
      "engage and inspire. \n",
      "Policy Advocacy \n",
      "Advocating for strong climate policies at the local, national, and international levels is \n",
      "essential for driving systemic change. This includes lobbying, public campaigns, and forming \n",
      "coalitions with like-minded organizations. Effective advocacy can lead to the adoption of \n",
      "ambitious and equitable climate policies. \n",
      "Youth Leadership \n",
      "Youth are powerful advocates for climate action. Empowering young people through\n",
      "\n",
      "\n",
      "Context 5:\n",
      "caps, and pollution controls. Enforcement and compliance are critical for their effectiveness. \n",
      "Local and Community Initiatives \n",
      "Urban Climate Action \n",
      "Cities play a pivotal role in climate action due to their high population densities and \n",
      "economic activities. Urban climate initiatives include sustainable transportation systems, \n",
      "green building standards, and climate-resilient infrastructure. Community engagement and \n",
      "participatory planning are essential for successful implementation. \n",
      "Community-Based Conservation\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Test fusion retrival\n",
    "query = \"What are the impacts of climate change on the environment?\"\n",
    "\n",
    "# Perform fusion retrieval\n",
    "top_docs = fusion_retrieval(vectorstore, bm25, query, k=5, alpha=0.5)\n",
    "docs_content = [doc.page_content for doc in top_docs]\n",
    "show_context(docs_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12ab9b366ad6c6c880fffbd1a9e1c0ba9825d2f9bd67635de77c6498f87926fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
