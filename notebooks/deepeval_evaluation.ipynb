{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Evaluation of RAG Systems using deepeval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code demonstrates the use of the deepeval library to perform comprehensive evaluations of Retrieval-Augmented Generation (RAG) systems. It covers various evaluation metrics and provides a framework for creating and running test cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build the basic RAG application on csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Customer Id</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Company</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Phone 1</th>\n",
       "      <th>Phone 2</th>\n",
       "      <th>Email</th>\n",
       "      <th>Subscription Date</th>\n",
       "      <th>Website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>DD37Cf93aecA6Dc</td>\n",
       "      <td>Sheryl</td>\n",
       "      <td>Baxter</td>\n",
       "      <td>Rasmussen Group</td>\n",
       "      <td>East Leonard</td>\n",
       "      <td>Chile</td>\n",
       "      <td>229.077.5154</td>\n",
       "      <td>397.884.0519x718</td>\n",
       "      <td>zunigavanessa@smith.info</td>\n",
       "      <td>2020-08-24</td>\n",
       "      <td>http://www.stephenson.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1Ef7b82A4CAAD10</td>\n",
       "      <td>Preston</td>\n",
       "      <td>Lozano</td>\n",
       "      <td>Vega-Gentry</td>\n",
       "      <td>East Jimmychester</td>\n",
       "      <td>Djibouti</td>\n",
       "      <td>5153435776</td>\n",
       "      <td>686-620-1820x944</td>\n",
       "      <td>vmata@colon.com</td>\n",
       "      <td>2021-04-23</td>\n",
       "      <td>http://www.hobbs.com/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index      Customer Id First Name Last Name          Company  \\\n",
       "0      1  DD37Cf93aecA6Dc     Sheryl    Baxter  Rasmussen Group   \n",
       "1      2  1Ef7b82A4CAAD10    Preston    Lozano      Vega-Gentry   \n",
       "\n",
       "                City   Country       Phone 1           Phone 2  \\\n",
       "0       East Leonard     Chile  229.077.5154  397.884.0519x718   \n",
       "1  East Jimmychester  Djibouti    5153435776  686-620-1820x944   \n",
       "\n",
       "                      Email Subscription Date                     Website  \n",
       "0  zunigavanessa@smith.info        2020-08-24  http://www.stephenson.com/  \n",
       "1           vmata@colon.com        2021-04-23       http://www.hobbs.com/  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load csv data\n",
    "file_path=\"data/customers-100.csv\"\n",
    "import pandas as pd\n",
    "data=pd.read_csv(file_path)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sunny\\Desktop\\Langchain_projects\\Q&A_chatbot\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Embeddings\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorstore\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "import faiss\n",
    "index=faiss.IndexFlatL2(len(embeddings.embed_query(\" \")))\n",
    "vector_store=FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Document loaders\n",
    "loader=CSVLoader(file_path)\n",
    "data=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['680d5dd0-f1c1-45f0-943b-22c7ea31066b',\n",
       " '6c0516b3-f49e-4a7a-aab7-a5f1efced207',\n",
       " '55db149f-2825-49a8-8ed6-562d8a4f9ba8',\n",
       " '06256581-18e6-4a1f-8199-01b8930e29f4',\n",
       " '804f2d12-8126-4354-abf7-16b43df2c12c',\n",
       " 'dfd18fb3-86b5-43b1-906e-9985c27e64ad',\n",
       " '816ed9f3-4d9d-4cf0-96cc-5dab612d4e67',\n",
       " 'e134199b-3256-4421-bc8f-d0a506420d31',\n",
       " '64c15675-2de0-40e8-ad12-10fe6633f5a0',\n",
       " '18ca37d8-944b-45b5-99d9-fd9f4adbe7e4',\n",
       " 'b15d6547-de63-44c9-a1b5-4220be24e23f',\n",
       " '3a475319-2ed2-4a85-b354-f238404ffe7c',\n",
       " '2325c1ef-159a-47d5-a286-20c3823a3a90',\n",
       " '5030e0df-aff7-4abb-a6f2-360859060931',\n",
       " 'bc755678-491a-491a-afb5-47fd019e1b47',\n",
       " 'ee306d9b-5a76-4289-b2b7-4a2efee4ce31',\n",
       " 'ffe7d1a1-3fb0-4ed9-90a4-aef2798fff80',\n",
       " '685289c8-fa5b-4b96-8032-e0a09cc1203b',\n",
       " '20f14c8d-32ef-4481-800b-a758b2b376c1',\n",
       " '06a9c1fb-f9b2-4d3c-99f6-75184503bac0',\n",
       " '9e415726-a940-4fd9-8f64-b7180240023a',\n",
       " '00067b5a-92ea-4435-a607-2cca8b7cc2fc',\n",
       " '1a7a1903-891d-4dee-b04d-c0da06e1a09d',\n",
       " '20d009fd-adcf-4cee-8a27-c95b2e36b8ba',\n",
       " 'd325bce6-be80-428f-b049-9614050644e2',\n",
       " 'f88e8835-2e5d-453f-ba0c-4775b66212e1',\n",
       " '0219e87d-3a82-4ce8-b46f-6b513ba86c9c',\n",
       " 'f142b021-dfc4-409d-8d43-4c536e1c2ff1',\n",
       " '1d425d1d-e23c-4cb6-82a0-aed59cc4aeb3',\n",
       " 'ced33ea9-3431-47c0-931a-30c21ddfff13',\n",
       " '6703f042-e178-4e78-aeea-2351b932523d',\n",
       " 'af3e8006-e968-4fcb-a123-4931396c749a',\n",
       " '9f8876e7-51d4-44f2-9684-a9114b245fa8',\n",
       " '19982a4b-e7ed-4f1e-b32b-c1e49ac7373d',\n",
       " '2bd9476f-85e1-455e-9cb0-29ac1596d726',\n",
       " '55c2469d-8816-4969-8484-70948f77b02f',\n",
       " 'f0989512-3cdd-4ab8-af74-f70c56ab0e24',\n",
       " '4ab1b196-8b57-47d3-bca9-3a66959048de',\n",
       " '3f410d04-7de0-476f-9bb9-2785e4174bc7',\n",
       " 'c7af8eaf-c54e-44b3-8163-4a5d7bf5d4d0',\n",
       " '5d9baf62-3ea8-4572-aec0-83bd49c36041',\n",
       " 'd099f2da-01eb-433c-a80d-2493532153f1',\n",
       " '140e7804-feea-4667-8e5a-5934aeb8bfe4',\n",
       " '6f0513d5-55de-4c26-a65a-c01fe834dfa4',\n",
       " '7f305714-6acc-49a8-b578-7514f1b08846',\n",
       " '1a3999a6-dad5-46d7-bf47-1a307e646577',\n",
       " '5dbb173c-937e-4a60-b97b-c37911abf303',\n",
       " '78312d47-b0f3-49b7-93dc-1efba7367bb4',\n",
       " '7f1bdd25-34e9-45c5-9555-38f2ff3a791a',\n",
       " 'cf3ab9a0-d1b3-40c4-b1ce-edeccb2f7ab8',\n",
       " '140760e0-ef3e-4191-a3ca-8cefe5f76823',\n",
       " '2fbd4c50-5413-40b3-a8ff-fcd84a6ebdef',\n",
       " 'c166c3af-8507-4e72-8446-f4bd0dced831',\n",
       " 'd8547248-7908-4832-85db-0c788b794d7c',\n",
       " '49782945-00e5-41cf-8374-c30d57422f86',\n",
       " 'd3cb96a1-493d-4689-8319-c5c1bb946021',\n",
       " 'a5b6cfeb-0661-4e00-aa62-ada3be4b3a55',\n",
       " '68f265b7-7e25-4a12-83ee-5c0b7f1448ef',\n",
       " 'e39b51c3-6e2d-40b4-8393-c0611ca777f2',\n",
       " '1e685542-5296-4e6e-ad98-c8a746150eb1',\n",
       " '899138f6-1ae8-4d19-8160-e23fc68cdbfc',\n",
       " 'ab1d5b37-512d-4f75-a3b8-66678a1aca61',\n",
       " 'e45144da-10c0-4618-8957-1929e7685786',\n",
       " 'd14a430d-b133-4d1e-8b50-af9219fa7fa7',\n",
       " '11fc7867-4055-4aa6-b921-e05bba2b21d7',\n",
       " '92217a49-1387-4c4f-b88e-2118e01120cc',\n",
       " '5ca193d7-494a-48a2-a716-be43541f5176',\n",
       " '6fda2d3e-c262-4a95-a04a-26564c134b90',\n",
       " '8448ca2b-68f6-4997-8c4e-a61dc69e7011',\n",
       " '34d769a0-c27d-452f-b49c-af78ca974028',\n",
       " 'b248896e-120e-4f71-b2cb-0edb5e836a6b',\n",
       " '6f61eed8-2f35-4bfa-a966-48f51a7d8be7',\n",
       " 'abdfbabd-5986-4558-97be-140d6ab3c97d',\n",
       " '806d13b3-7116-4d8e-89ca-a224ca8ce497',\n",
       " '1bdbe3c6-389a-4e7f-93fb-f2941d3d7f14',\n",
       " 'd76bc715-89d7-4698-a2e5-7407946f4cc5',\n",
       " '77e949e9-dc46-4eac-af9d-58d5631dbfab',\n",
       " 'c4ff85c3-5131-4f2e-90ea-9d2aa85dbb60',\n",
       " '42f94e37-dc22-4e8f-8cce-ed8d7ef507e9',\n",
       " 'aad2d28b-8219-4749-b9a6-37bbe7f42c79',\n",
       " '882e7e39-d1b6-4533-ac10-151d65766efa',\n",
       " '88a33b61-1bcb-4df8-aaf3-4a3b319f9766',\n",
       " 'ecae3643-0a1d-46fa-abf5-f96bbf7b0788',\n",
       " '4c2a1b23-f89d-4f1a-8467-aea37fda1579',\n",
       " 'c7b94ef7-59b7-4985-a8ac-7f93fd1a03b9',\n",
       " 'fb9fa8cc-b192-453f-93cb-f8c8367525d5',\n",
       " '4eac13a8-0999-48ed-b13f-381b07bc59c8',\n",
       " 'c3d23354-df05-4f10-af8e-e09409ee2e7b',\n",
       " '8f5b1084-9470-4d6e-b137-148864fa3bc3',\n",
       " 'bbadb271-0bd9-4ced-94f6-291f1ecc0d9a',\n",
       " 'dd06b17a-cf61-483c-bb3d-ee4610fa4b97',\n",
       " 'eae87e44-95cb-41ce-a99f-647940dd4929',\n",
       " '64ed2dac-fdee-4f82-ac3e-14c1729d86ff',\n",
       " '04cab718-1732-455a-a078-0df7e12c6444',\n",
       " '36443845-4781-4c88-a959-3131da8d85d4',\n",
       " 'b6adfe47-8662-44e4-80b6-add3d75ef903',\n",
       " 'e4e0090c-5103-488d-944d-1b4aede77dde',\n",
       " '27e3becb-2487-4a24-b6eb-adc9f8ade5ef',\n",
       " 'f3bcd15a-e780-4926-8f51-90dc273b381e',\n",
       " 'b891c709-feda-490c-9f1b-746e9672feb2']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(documents=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retriever\n",
    "retriever=vector_store.as_retriever(search_kwargs={'k':2})\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"Llama3-8b-8192\")\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "prompt=PromptTemplate(\n",
    "    template=\"\"\" \n",
    "    You are assistant for question answering tasks.\n",
    "    Use the following piece of retreived context to answer\n",
    "    the question.If you don't know the answer, say that you don't know.\n",
    "    keep the answer concise.\n",
    "    {context}\n",
    "    Question:{question}\n",
    "    \"\"\",\n",
    "    input_variables=['context','question']\n",
    ")\n",
    "\n",
    "#Building chain\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def format_docs(retrieved_docs):\n",
    "    context_text=\"\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "    return context_text\n",
    "\n",
    "parllel_chain=RunnableParallel({\n",
    "    'context':retriever | RunnableLambda(format_docs),\n",
    "    'question': RunnablePassthrough()\n",
    "})\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "rag_chain = parllel_chain | prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheryl Baxter works for Rasmussen Group.\n"
     ]
    }
   ],
   "source": [
    "answer=rag_chain.invoke('which company does sheryl Baxter work for?')\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default RAG Metrics using Evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sunny\\Desktop\\Langchain_projects\\Q&A_chatbot\\venv\\lib\\site-packages\\deepeval\\__init__.py:54: UserWarning: You are using deepeval version 2.6.7, however version 2.9.3 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
    "from deepeval.metrics import (\n",
    "    AnswerRelevancyMetric,\n",
    "    FaithfulnessMetric,\n",
    "    ContextualPrecisionMetric,\n",
    "    ContextualRecallMetric,\n",
    "    ContextualRelevancyMetric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\sunny\\Desktop\\Langchain_projects\\Q&amp;A_chatbot\\venv\\lib\\site-packages\\rich\\live.py:231: UserWarning: install\n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\sunny\\Desktop\\Langchain_projects\\Q&A_chatbot\\venv\\lib\\site-packages\\rich\\live.py:231: UserWarning: install\n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "The score is 1.00 because the output is perfectly relevant and directly answers the input without any irrelevant statements. Great job on maintaining such high relevancy!\n"
     ]
    }
   ],
   "source": [
    "metric = AnswerRelevancyMetric(\n",
    "    threshold=0.7,\n",
    "    include_reason=True\n",
    ")\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input = \"which company does sheryl Baxter work for?\",\n",
    "    actual_output=\"Sheryl Baxter works for Rasmussen Group\"\n",
    ")\n",
    "\n",
    "#Run metric as standalone\n",
    "metric.measure(test_case)\n",
    "print(metric.score)\n",
    "print(metric.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|100% (1/1) [Time Taken: 00:03,  3.13s/test case]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.7, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the provided output perfectly matches the input question with high precision and no irrelevant statements., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: which company does sheryl Baxter work for?\n",
      "  - actual output: Sheryl Baxter works for Rasmussen Group\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Tests finished üéâ! Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval login'</span> to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "‚ú®üëÄ Looking for a place for your LLM test data to live üè°‚ù§Ô∏è ? Use <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span> to get &amp; share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run <span style=\"color: #008080; text-decoration-color: #008080\">'deepeval login'</span> in the CLI. \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Tests finished üéâ! Run \u001b[1;32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "‚ú®üëÄ Looking for a place for your LLM test data to live üè°‚ù§Ô∏è ? Use \u001b[38;2;106;0;255mConfident AI\u001b[0m to get & share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run \u001b[36m'deepeval login'\u001b[0m in the CLI. \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(test_results=[TestResult(name='test_case_0', success=True, metrics_data=[MetricData(name='Answer Relevancy', threshold=0.7, success=True, score=1.0, reason='The score is 1.00 because the provided output perfectly matches the input question with high precision and no irrelevant statements.', strict_mode=False, evaluation_model='gpt-4o', error=None, evaluation_cost=0.0034175000000000004, verbose_logs='Statements:\\n[\\n    \"Sheryl Baxter works for Rasmussen Group.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]')], conversational=False, multimodal=False, input='which company does sheryl Baxter work for?', actual_output='Sheryl Baxter works for Rasmussen Group', expected_output=None, context=None, retrieval_context=None, additional_metadata=None)], confident_link=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can use evaluate function to run the metrics\n",
    "evaluate(test_cases=[test_case],metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">correctness </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">(</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">)</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mcorrectness \u001b[0m\u001b[1;38;2;106;0;255m(\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m)\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 1 test case(s) in parallel: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|100% (1/1) [Time Taken: 00:04,  4.43s/test case]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚ùå correctness (GEval) (score: 0.23650124897758448, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The actual output introduces ambiguity by suggesting both the cat and the dog, while the expected output clearly states the cat ran up the tree., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: The dog chased the cat up the tree, who ran up the tree?\n",
      "  - actual output: It depends, some might consider the cat, while others might argue the dog.\n",
      "  - expected output: The cat.\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "correctness (GEval): 0.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Tests finished üéâ! Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval login'</span> to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "‚ú®üëÄ Looking for a place for your LLM test data to live üè°‚ù§Ô∏è ? Use <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span> to get &amp; share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run <span style=\"color: #008080; text-decoration-color: #008080\">'deepeval login'</span> in the CLI. \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Tests finished üéâ! Run \u001b[1;32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI.\n",
       " \n",
       "‚ú®üëÄ Looking for a place for your LLM test data to live üè°‚ù§Ô∏è ? Use \u001b[38;2;106;0;255mConfident AI\u001b[0m to get & share testing reports, \n",
       "experiment with models/prompts, and catch regressions for your LLM system. Just run \u001b[36m'deepeval login'\u001b[0m in the CLI. \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(test_results=[TestResult(name='test_case_0', success=False, metrics_data=[MetricData(name='correctness (GEval)', threshold=0.5, success=False, score=0.23650124897758448, reason='The actual output introduces ambiguity by suggesting both the cat and the dog, while the expected output clearly states the cat ran up the tree.', strict_mode=False, evaluation_model='gpt-4o', error=None, evaluation_cost=0.00225, verbose_logs='Criteria:\\nDetermine whether the actual output is factually correct based on the expected output. \\n \\nEvaluation Steps:\\n[\\n    \"Compare the factual details in the actual output against the expected output.\",\\n    \"Identify any discrepancies between the actual output and the expected output.\",\\n    \"Evaluate whether the actual output provides accurate information as specified in the expected output.\",\\n    \"Determine if the actual output meets the factual correctness criteria based on the expected output.\"\\n]')], conversational=False, multimodal=False, input='The dog chased the cat up the tree, who ran up the tree?', actual_output='It depends, some might consider the cat, while others might argue the dog.', expected_output='The cat.', context=None, retrieval_context=None, additional_metadata=None)], confident_link=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## GEval metric\n",
    "from deepeval.metrics import GEval\n",
    "\n",
    "correctness_metric = GEval(\n",
    "    name=\"correctness\",\n",
    "    criteria=\"Determine whether the actual output is factually correct based on the expected output.\",\n",
    "    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.EXPECTED_OUTPUT]\n",
    ")\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input=\"The dog chased the cat up the tree, who ran up the tree?\",\n",
    "    actual_output=\"It depends, some might consider the cat, while others might argue the dog.\",\n",
    "    expected_output=\"The cat.\"\n",
    ")\n",
    "\n",
    "evaluate(test_cases=[test_case], metrics=[correctness_metric])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
